{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8873b8",
   "metadata": {},
   "source": [
    "#### Grundbegriffe\n",
    "- precision = TP/(TP+FP)\n",
    "- recall = TP/(TP+FN)\n",
    "- F1 (Durchschnitt aus precision und recall) = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e70a5e6",
   "metadata": {},
   "source": [
    "#### Calculating Metrics in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0e6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a485ad",
   "metadata": {},
   "source": [
    "accuracy, precision, recall und f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef06f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8049605411499436\n",
      "precision: 0.7734627831715211\n",
      "recall: 0.6988304093567251\n",
      "f1 score 0.7342549923195083\n"
     ]
    }
   ],
   "source": [
    "#metric functions aus sklearn importieren\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#nimmt wahre werte des ziels heraus und und vorhergesagte werte des ziels\n",
    "print('accuracy:', accuracy_score(y, y_pred)) #80% vorhersagen korrekt\n",
    "print('precision:', precision_score(y, y_pred)) #78% der positiven vorhersagen korrekt\n",
    "print('recall:', recall_score(y, y_pred)) #68% der fälle vom model korrekt vorhergesagt\n",
    "print('f1 score', f1_score(y, y_pred)) #73% für durchschnitt aus precision und recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2418be",
   "metadata": {},
   "source": [
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c378d5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[475  70]\n",
      " [103 239]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix funktion, die die 4 werte ausgeben kann zu true positives, false poitives, true negatives, false negatives\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y, y_pred))\n",
    "#andersherum: negativ kommt bei sklearn immer zuerst, also tatsächlich negativ/vorhersage negativ = 475, tatsächlich negativ/vorhersage positiv = 70, tat pos/vorh neg = 103, tat pos/vorh pos = 239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab50f5f",
   "metadata": {},
   "source": [
    "#### Training and Testing\n",
    "- 70-80% der Daten kommen ins Training Set \n",
    "- 20-30% der Daten landen im Test Set\n",
    "- Beispiel: 150 datapoints training vs. 50 datapoints test\n",
    "- sklearn kann Daten in Test- und Training-Set splitten (default = 75 : 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1917b",
   "metadata": {},
   "source": [
    "Training-Set erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27e7404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset: (887, 6) (887,)\n",
      "training set: (532, 6) (532,)\n",
      "test set: (355, 6) (355,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#training-set größe/verhältnis ändern über train_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6)\n",
    "\n",
    "#größe der datensets anzeigen lassen über shape\n",
    "print(\"whole dataset:\", X.shape, y.shape)\n",
    "print(\"training set:\", X_train.shape, y_train.shape)\n",
    "print(\"test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb3fe7",
   "metadata": {},
   "source": [
    "Trainingsset über Sklearn-Model erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7123e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7882882882882883\n",
      "precision: 0.7468354430379747\n",
      "recall: 0.686046511627907\n",
      "f1 score: 0.7151515151515152\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# building the model, dieses mal aber über training-set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model über X_test\n",
    "# alle metrics testen lassen: print(\"accuracy:\", model.score(X_test, y_test))\n",
    "#ähnlichkeiten zu echtwerten ergeben sich nur, wenn man das ganze datenset abfragt\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f5656be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train2 [[2, 2], [4, 4], [1, 1]]\n",
      "X_test2 [[3, 3]]\n",
      "\n",
      "Immer die gleichen Durchläufe über random_state=\n",
      "X_train2 [[3, 3], [1, 1], [4, 4]]\n",
      "X_test2 [[2, 2]]\n"
     ]
    }
   ],
   "source": [
    "#erzielt nie die gleich ergebnisse bei wiederholten durchläufen\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2 = [[1, 1], [2, 2], [3, 3], [4, 4]]\n",
    "y2 = [0, 0, 1, 1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2)\n",
    "print('X_train2', X_train2)\n",
    "print('X_test2', X_test2)\n",
    "\n",
    "\n",
    "print('\\nImmer die gleichen Durchläufe über random_state=')\n",
    "#um immer den gleichen split zu kriegen (ergebnisse normal immer random): random_state= verwenden\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2 = [[1,1], [2,2], [3,3], [4,4]]\n",
    "y2 = [0,0,1,1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=27)\n",
    "print('X_train2', X_train2)\n",
    "print('X_test2', X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09452dc",
   "metadata": {},
   "source": [
    "#### Foundations for the ROC Curve\n",
    "- Grenze i.d.R. zwischen 0 und 1\n",
    "- höhere Grenze: weniger Positive, aber dafür Vorhersagen mit höherer Wahrscheinlichkeit korrekt\n",
    "- niedrigere Grenze: mehr Positive, aber Präzision dafür niedriger\n",
    "- ROC Curve zeigt alle positiven Modell und ihre Werte\n",
    "- sensitivity (=recall, TP rate): TP/(TP+FN)\n",
    "- specificity (TN rate): TN/(TN+FP) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370770b",
   "metadata": {},
   "source": [
    "Sensitivity & Specificity in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2090ff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensivity score: 0.686046511627907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensitivity_score = recall_score\n",
    "print(f'sensivity score:', sensitivity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03713eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specifity score: (array([0.81118881, 0.74683544]), array([0.85294118, 0.68604651]), array([0.83154122, 0.71515152]), array([136,  86], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "print(f'specifity score:', precision_recall_fscore_support(y_test, y_pred))\n",
    "#ergebnis: 2.array ist der recall (wert1=negative=specificity, wert2=positive=sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d2a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0]\n",
    "\n",
    "print(specificity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0480b03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity: 0.6829268292682927\n",
      "specificity: 0.9214285714285714\n"
     ]
    }
   ],
   "source": [
    "#nochmal gesamter code\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_recall_fscore_support\n",
    "\n",
    "sensitivity_score = recall_score\n",
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0]\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"sensitivity:\", sensitivity_score(y_test, y_pred))\n",
    "print(\"specificity:\", specificity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c3db4",
   "metadata": {},
   "source": [
    "Adjusting the Logistic Regression Threshold in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19650e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46054667, 0.53945333],\n",
       "       [0.88809994, 0.11190006],\n",
       "       [0.13520602, 0.86479398],\n",
       "       [0.6249716 , 0.3750284 ],\n",
       "       [0.73722985, 0.26277015],\n",
       "       [0.85687045, 0.14312955],\n",
       "       [0.84133126, 0.15866874],\n",
       "       [0.10657197, 0.89342803],\n",
       "       [0.12609776, 0.87390224],\n",
       "       [0.42023636, 0.57976364],\n",
       "       [0.92436647, 0.07563353],\n",
       "       [0.83523899, 0.16476101],\n",
       "       [0.13698996, 0.86301004],\n",
       "       [0.90217298, 0.09782702],\n",
       "       [0.60512299, 0.39487701],\n",
       "       [0.79564747, 0.20435253],\n",
       "       [0.17515531, 0.82484469],\n",
       "       [0.46654899, 0.53345101],\n",
       "       [0.24196022, 0.75803978],\n",
       "       [0.89247698, 0.10752302],\n",
       "       [0.28467585, 0.71532415],\n",
       "       [0.87814606, 0.12185394],\n",
       "       [0.86200163, 0.13799837],\n",
       "       [0.87075261, 0.12924739],\n",
       "       [0.86658841, 0.13341159],\n",
       "       [0.22589812, 0.77410188],\n",
       "       [0.85172027, 0.14827973],\n",
       "       [0.8516764 , 0.1483236 ],\n",
       "       [0.56230304, 0.43769696],\n",
       "       [0.64036605, 0.35963395],\n",
       "       [0.89256694, 0.10743306],\n",
       "       [0.04988467, 0.95011533],\n",
       "       [0.51041539, 0.48958461],\n",
       "       [0.87120539, 0.12879461],\n",
       "       [0.94761331, 0.05238669],\n",
       "       [0.91062418, 0.08937582],\n",
       "       [0.03650848, 0.96349152],\n",
       "       [0.59265943, 0.40734057],\n",
       "       [0.62739736, 0.37260264],\n",
       "       [0.95937485, 0.04062515],\n",
       "       [0.22725317, 0.77274683],\n",
       "       [0.9092091 , 0.0907909 ],\n",
       "       [0.35264465, 0.64735535],\n",
       "       [0.54176752, 0.45823248],\n",
       "       [0.44435352, 0.55564648],\n",
       "       [0.82171299, 0.17828701],\n",
       "       [0.74247743, 0.25752257],\n",
       "       [0.89824845, 0.10175155],\n",
       "       [0.8618294 , 0.1381706 ],\n",
       "       [0.26830499, 0.73169501],\n",
       "       [0.78056542, 0.21943458],\n",
       "       [0.84654287, 0.15345713],\n",
       "       [0.69982798, 0.30017202],\n",
       "       [0.32695796, 0.67304204],\n",
       "       [0.8511667 , 0.1488333 ],\n",
       "       [0.72243824, 0.27756176],\n",
       "       [0.07465501, 0.92534499],\n",
       "       [0.04492801, 0.95507199],\n",
       "       [0.87393721, 0.12606279],\n",
       "       [0.33717668, 0.66282332],\n",
       "       [0.85178168, 0.14821832],\n",
       "       [0.14217315, 0.85782685],\n",
       "       [0.84102655, 0.15897345],\n",
       "       [0.92328972, 0.07671028],\n",
       "       [0.85160798, 0.14839202],\n",
       "       [0.90966468, 0.09033532],\n",
       "       [0.96516889, 0.03483111],\n",
       "       [0.68062879, 0.31937121],\n",
       "       [0.37301669, 0.62698331],\n",
       "       [0.49744105, 0.50255895],\n",
       "       [0.69670166, 0.30329834],\n",
       "       [0.87148833, 0.12851167],\n",
       "       [0.07718478, 0.92281522],\n",
       "       [0.60170171, 0.39829829],\n",
       "       [0.61536673, 0.38463327],\n",
       "       [0.04765439, 0.95234561],\n",
       "       [0.05302551, 0.94697449],\n",
       "       [0.95973976, 0.04026024],\n",
       "       [0.84931225, 0.15068775],\n",
       "       [0.7237028 , 0.2762972 ],\n",
       "       [0.99575381, 0.00424619],\n",
       "       [0.88849973, 0.11150027],\n",
       "       [0.28460473, 0.71539527],\n",
       "       [0.85758199, 0.14241801],\n",
       "       [0.28483386, 0.71516614],\n",
       "       [0.90709047, 0.09290953],\n",
       "       [0.51997123, 0.48002877],\n",
       "       [0.91875672, 0.08124328],\n",
       "       [0.60923484, 0.39076516],\n",
       "       [0.89636119, 0.10363881],\n",
       "       [0.94247837, 0.05752163],\n",
       "       [0.31752819, 0.68247181],\n",
       "       [0.73816464, 0.26183536],\n",
       "       [0.95340159, 0.04659841],\n",
       "       [0.37742295, 0.62257705],\n",
       "       [0.83558763, 0.16441237],\n",
       "       [0.93778963, 0.06221037],\n",
       "       [0.69670166, 0.30329834],\n",
       "       [0.17416171, 0.82583829],\n",
       "       [0.80299354, 0.19700646],\n",
       "       [0.13201852, 0.86798148],\n",
       "       [0.92443693, 0.07556307],\n",
       "       [0.91885069, 0.08114931],\n",
       "       [0.90372843, 0.09627157],\n",
       "       [0.10674303, 0.89325697],\n",
       "       [0.23086962, 0.76913038],\n",
       "       [0.86616081, 0.13383919],\n",
       "       [0.82705086, 0.17294914],\n",
       "       [0.88855362, 0.11144638],\n",
       "       [0.9205055 , 0.0794945 ],\n",
       "       [0.62238349, 0.37761651],\n",
       "       [0.10211858, 0.89788142],\n",
       "       [0.86956935, 0.13043065],\n",
       "       [0.51857685, 0.48142315],\n",
       "       [0.89507414, 0.10492586],\n",
       "       [0.84642703, 0.15357297],\n",
       "       [0.89254029, 0.10745971],\n",
       "       [0.11524087, 0.88475913],\n",
       "       [0.86680377, 0.13319623],\n",
       "       [0.66905534, 0.33094466],\n",
       "       [0.2933286 , 0.7066714 ],\n",
       "       [0.12007607, 0.87992393],\n",
       "       [0.8567767 , 0.1432233 ],\n",
       "       [0.84114417, 0.15885583],\n",
       "       [0.49063142, 0.50936858],\n",
       "       [0.44640149, 0.55359851],\n",
       "       [0.77480187, 0.22519813],\n",
       "       [0.91062418, 0.08937582],\n",
       "       [0.74856102, 0.25143898],\n",
       "       [0.64318742, 0.35681258],\n",
       "       [0.72220968, 0.27779032],\n",
       "       [0.96090819, 0.03909181],\n",
       "       [0.82171299, 0.17828701],\n",
       "       [0.23215475, 0.76784525],\n",
       "       [0.91394137, 0.08605863],\n",
       "       [0.82642958, 0.17357042],\n",
       "       [0.95064403, 0.04935597],\n",
       "       [0.89656752, 0.10343248],\n",
       "       [0.57170942, 0.42829058],\n",
       "       [0.88615731, 0.11384269],\n",
       "       [0.94355124, 0.05644876],\n",
       "       [0.59883189, 0.40116811],\n",
       "       [0.82485271, 0.17514729],\n",
       "       [0.10489908, 0.89510092],\n",
       "       [0.12055179, 0.87944821],\n",
       "       [0.87597386, 0.12402614],\n",
       "       [0.71190419, 0.28809581],\n",
       "       [0.08343299, 0.91656701],\n",
       "       [0.93670024, 0.06329976],\n",
       "       [0.82770652, 0.17229348],\n",
       "       [0.43972226, 0.56027774],\n",
       "       [0.28838134, 0.71161866],\n",
       "       [0.91730349, 0.08269651],\n",
       "       [0.92597457, 0.07402543],\n",
       "       [0.92610303, 0.07389697],\n",
       "       [0.25730214, 0.74269786],\n",
       "       [0.72341675, 0.27658325],\n",
       "       [0.87823016, 0.12176984],\n",
       "       [0.91512624, 0.08487376],\n",
       "       [0.91410443, 0.08589557],\n",
       "       [0.05760764, 0.94239236],\n",
       "       [0.94078778, 0.05921222],\n",
       "       [0.16335036, 0.83664964],\n",
       "       [0.92524494, 0.07475506],\n",
       "       [0.94393638, 0.05606362],\n",
       "       [0.94597961, 0.05402039],\n",
       "       [0.10242644, 0.89757356],\n",
       "       [0.62161726, 0.37838274],\n",
       "       [0.68571592, 0.31428408],\n",
       "       [0.89585796, 0.10414204],\n",
       "       [0.04083076, 0.95916924],\n",
       "       [0.18784982, 0.81215018],\n",
       "       [0.45255539, 0.54744461],\n",
       "       [0.67787676, 0.32212324],\n",
       "       [0.8921109 , 0.1078891 ],\n",
       "       [0.23953657, 0.76046343],\n",
       "       [0.88854217, 0.11145783],\n",
       "       [0.10987886, 0.89012114],\n",
       "       [0.94019631, 0.05980369],\n",
       "       [0.93882562, 0.06117438],\n",
       "       [0.79577709, 0.20422291],\n",
       "       [0.49522506, 0.50477494],\n",
       "       [0.75867113, 0.24132887],\n",
       "       [0.90726986, 0.09273014],\n",
       "       [0.90365285, 0.09634715],\n",
       "       [0.0606447 , 0.9393553 ],\n",
       "       [0.56528417, 0.43471583],\n",
       "       [0.82987278, 0.17012722],\n",
       "       [0.86445244, 0.13554756],\n",
       "       [0.46033957, 0.53966043],\n",
       "       [0.84642703, 0.15357297],\n",
       "       [0.33927963, 0.66072037],\n",
       "       [0.87603423, 0.12396577],\n",
       "       [0.84648272, 0.15351728],\n",
       "       [0.70686053, 0.29313947],\n",
       "       [0.85126347, 0.14873653],\n",
       "       [0.47905786, 0.52094214],\n",
       "       [0.92539647, 0.07460353],\n",
       "       [0.23953657, 0.76046343],\n",
       "       [0.8964386 , 0.1035614 ],\n",
       "       [0.65157863, 0.34842137],\n",
       "       [0.53351587, 0.46648413],\n",
       "       [0.8463879 , 0.1536121 ],\n",
       "       [0.32585952, 0.67414048],\n",
       "       [0.86966223, 0.13033777],\n",
       "       [0.67288834, 0.32711166],\n",
       "       [0.66905534, 0.33094466],\n",
       "       [0.37932435, 0.62067565],\n",
       "       [0.63392062, 0.36607938],\n",
       "       [0.95150915, 0.04849085],\n",
       "       [0.90433727, 0.09566273],\n",
       "       [0.95359139, 0.04640861],\n",
       "       [0.20277597, 0.79722403],\n",
       "       [0.03729447, 0.96270553],\n",
       "       [0.72358421, 0.27641579],\n",
       "       [0.07284674, 0.92715326],\n",
       "       [0.54861358, 0.45138642],\n",
       "       [0.88858229, 0.11141771],\n",
       "       [0.84113797, 0.15886203],\n",
       "       [0.68741757, 0.31258243],\n",
       "       [0.72019731, 0.27980269],\n",
       "       [0.88458604, 0.11541396]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wahl einer anderen grenze statt 0.5: predict_proba()-funktion\n",
    "model.predict_proba(X_test)\n",
    "\n",
    "#ergebnis: beide werte addiert ergeben 1\n",
    "#linker_wert=0(gestorben), rechter wert=1(überlebt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20811835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grenze bei 75% definieren:\n",
    "y_pred = model.predict_proba(X_test)[:,1] > 0.75\n",
    "\n",
    "#ergebnis: weniger pos, aber mehr neg (man muss sich schon mehrerer pos-werte bewusst sein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bd5b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9230769230769231\n",
      "recall: 0.43902439024390244\n"
     ]
    }
   ],
   "source": [
    "#prediction durchführen über precision und recall\n",
    "print('precision:', precision_score(y_test, y_pred))\n",
    "print('recall:', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0807b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8723404255319149\n",
      "recall: 0.4823529411764706\n"
     ]
    }
   ],
   "source": [
    "#gesamter beispielcode:\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:, 1] > 0.75\n",
    "\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd883b0",
   "metadata": {},
   "source": [
    "#### The ROC Curve\n",
    "- ROC ist Graph bestehend aus Werten von \"specificity\" und \"sensitivity\"\n",
    "- Vorgehen: Logistic Regression Model -> Kalkulation von specificity und sensitivity\n",
    "- jede vorhergesagte Wahrscheinlichkeit wird als \"Grenze\" verwendet\n",
    "- specificity: FP rate auf x-Achse\n",
    "- sensitivity: TP rate auf y-Achse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63047aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba[:,1]) #fp/tp\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--') #linie als richtlinie, wie weit das modell von den zufalls-werten entfernt ist\n",
    "plt.xlim([0.0, 1.0]) #höchstwert der x-achse\n",
    "plt.ylim([0.0, 1.0]) #höchstwert der y-achse\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.show()\n",
    "\n",
    "#roc curve interpretation: kurve sollte nie unter linie fallen\n",
    "#je nachdem was eher gebraucht wird, modell(punkt auf random-kurve) nach specificity oder sensitivity wählen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5828b6",
   "metadata": {},
   "source": [
    "Bereich unter Kurve berechnen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a4e514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556032632030915"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, y_pred_proba[:,1]) #auch = area under curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d414a",
   "metadata": {},
   "source": [
    "Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96e17016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score: 0.8741724738675959\n",
      "model 2 AUC score: 0.8352787456445991\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "print(\"model 1 AUC score:\", roc_auc_score(y_test, y_pred_proba1[:, 1]))\n",
    "\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train[:, 0:2], y_train)\n",
    "y_pred_proba2 = model2.predict_proba(X_test[:, 0:2])\n",
    "print(\"model 2 AUC score:\", roc_auc_score(y_test, y_pred_proba2[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c2067a",
   "metadata": {},
   "source": [
    "#### k-fold Cross Validation\n",
    "- Set aufteilen in z.B. 5 Teilsets\n",
    "- Bsp.: 100 Daten -> 4x 20 Train Data + 1x 20 Test Data\n",
    "- Ziel: genaue Messungen erhalten für Maße (accuracy, precision, recall) durch das Erstellen von extra Modellen => um sicher zu sein, dass die Ergebnisse auch zuverlässig sind bzw. stimmen sollten\n",
    "- bei sehr großen Daten: splitten sinnvoll wegen Rechenleistung\n",
    "- nach 5er-split k-fold CV: neues Modell aus den ganzen Daten zusammenbauen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9fee1",
   "metadata": {},
   "source": [
    "Bisheriger Code aus Lektion 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14195f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 0.77477\n",
      "precision: 0.75000\n",
      "   recall: 0.66667\n",
      " f1 score: 0.70588\n",
      "0.30110883712768555s\n"
     ]
    }
   ],
   "source": [
    "#berechnet dauer für codedurchlauf\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# building the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\" accuracy: {0:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"precision: {0:.5f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"   recall: {0:.5f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\" f1 score: {0:.5f}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "#Ergebnis: output variiert aktuell noch ziemlich stark zwischen acc(0.79-0.84), prec(0.75-0.81), recall(0.63-0.75)\n",
    "\n",
    "end = time.time()\n",
    "print(f'{abs(start-end)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d492f711",
   "metadata": {},
   "source": [
    "#### k-fold Cross Validation in Sklearn = Praktische Umsetzung k-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d8523",
   "metadata": {},
   "source": [
    "KFold Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d49bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 5] [3 4]\n",
      "[1 2 3 4] [0 5]\n",
      "[0 3 4 5] [1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "#datenset mit nur 6 datenpunkten und 2 features über k-fold cv\n",
    "#erste 6 reihen aus titanic\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "X = df[['Age', 'Fare']].values[:6]\n",
    "y = df['Survived'].values[:6]\n",
    "\n",
    "#k-fold klasse initiieren mit k als anzahl der daten-container (chunks)\n",
    "#shuffle=True sorgt für zufallsordnung der datenauswahl\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "#einteilung in listen noch nötig, da gesplittet wird\n",
    "for train, test in kf.split(X):\n",
    "    print(train, test)\n",
    "    \n",
    "#print(list(kf.split(X))) #als listen nacheinander\n",
    "\n",
    "#ergebnis: 3 training-sets und 3 test-sets (achtung: werte können nicht jeweils doppelt vorkommen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa6922",
   "metadata": {},
   "source": [
    "Trainings- und Test-Sets über die Folds erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b48a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 3, 4, 5]), array([1, 2]))\n"
     ]
    }
   ],
   "source": [
    "#ersten split ausgeben\n",
    "splits = list(kf.split(X))\n",
    "first_split = splits[0]\n",
    "print(first_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e345be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set indices: [0 3 4 5]\n",
      "test set indices: [1 2]\n"
     ]
    }
   ],
   "source": [
    "#zwischen trainings-set und test-set unterscheiden\n",
    "train_indices, test_indices = first_split\n",
    "print(\"training set indices:\", train_indices)\n",
    "print(\"test set indices:\", test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fc7b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X und y train/test über indizes erzeugen\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c5466cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[22.      7.25  ]\n",
      " [35.     53.1   ]\n",
      " [35.      8.05  ]\n",
      " [27.      8.4583]]\n",
      "y_train [0 1 0 0]\n",
      "X_test\n",
      "[[38.     71.2833]\n",
      " [26.      7.925 ]]\n",
      "y_test [1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train\")\n",
    "print(X_train)\n",
    "print(\"y_train\", y_train)\n",
    "print(\"X_test\")\n",
    "print(X_test)\n",
    "print(\"y_test\", y_test)\n",
    "\n",
    "#ergebnis: 4 der datenpunkte in x_train und ihre ziel-werte in y_train => restliche 2 datenpunkte in x_test und ihre ziel-werte in y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba5b5d",
   "metadata": {},
   "source": [
    "Das Modell aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "835d47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7696629213483146\n"
     ]
    }
   ],
   "source": [
    "#ganzes datenset wird verwendet (nur so aussagekräftig genug)\n",
    "#modell wird verwendet für vorhersage\n",
    "#k-fold cv mit k=5  \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "splits = list(kf.split(X))\n",
    "train_indices, test_indices = splits[0]\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74051389",
   "metadata": {},
   "source": [
    "Alle Folds ausgeben lassen (= iterieren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ec64369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop over folds: [0.8314606741573034, 0.7865168539325843, 0.7853107344632768, 0.807909604519774, 0.768361581920904]\n",
      "final score calculated by mean: 0.7959118897987685\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "#iterieren, um alle werte zu kriegen, nicht wie zuvor nur 1 wert\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "\n",
    "print(f'loop over folds:', scores)\n",
    "\n",
    "print(f'final score calculated by mean:', np.mean(scores))\n",
    "\n",
    "#ergebnis: nach jeder code-ausführung anders => durchschnitt weicht aber kaum ab "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5eeec",
   "metadata": {},
   "source": [
    "#### Modell-Vergleich\n",
    "- Beispiel: Vergleich ganzes_Datenset vs. Pclass_Age_Sex vs. Fare_Age\n",
    "- Evalluierungs-Techniken nötig, um zwischen mehreren Modell-Optionen zu unterscheiden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1688a",
   "metadata": {},
   "source": [
    "Modelle über Scikit-learn aufbauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5b69636e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with all features\n",
      "accuracy: 0.8004380118072749\n",
      "precision: 0.7651492951492951\n",
      "recall: 0.6970200725511578\n",
      "f1 score: 0.7282691107630734\n",
      "\n",
      "Logistic Regression with Pclass, Sex & Age features\n",
      "accuracy: 0.7970799212848346\n",
      "precision: 0.7524251452995642\n",
      "recall: 0.7101586025725499\n",
      "f1 score: 0.7281690375202344\n",
      "\n",
      "Logistic Regression with Fare & Age features\n",
      "accuracy: 0.658414270297721\n",
      "precision: 0.6561639578692627\n",
      "recall: 0.24885830999066294\n",
      "f1 score: 0.35559417971461543\n",
      "LogisticRegression()\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#vorbereitung der daten\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "\n",
    "#k-fold objekt ersetllen\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#3 feature matrizen erstellen, alle mit dem gleichen ziel y\n",
    "X1 = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "X2 = df[['Pclass', 'male', 'Age']].values\n",
    "X3 = df[['Fare', 'Age']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "#verwendung des k-fold objekts um accuracy/precision/recall/f1 zu berechnen\n",
    "def score_model(X, y, kf):\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "    print(\"accuracy:\", np.mean(accuracy_scores))\n",
    "    print(\"precision:\", np.mean(precision_scores))\n",
    "    print(\"recall:\", np.mean(recall_scores))\n",
    "    print(\"f1 score:\", np.mean(f1_scores))\n",
    "\n",
    "print(\"Logistic Regression with all features\")\n",
    "score_model(X1, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Pclass, Sex & Age features\")\n",
    "score_model(X2, y, kf)\n",
    "print()\n",
    "print(\"Logistic Regression with Fare & Age features\")\n",
    "score_model(X3, y, kf)\n",
    "\n",
    "#ergebnis: erste beide modelle mit ähnlichen ergebnissen, beim 3.modell fehlt\n",
    "#das geschlecht => aussage: frauen überleben häufiger =>\n",
    "#=> einfacheres modell wählen (da sowieso ähnlich dem 1.modell)\n",
    "#=> modell2(X2) ist die beste wahl\n",
    "\n",
    "#final model erstellen\n",
    "model = LogisticRegression()\n",
    "print(model.fit(X1, y))\n",
    "\n",
    "#vorhersage erstellen\n",
    "print(model.predict([[3, False, 25, 0, 1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679fc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439620a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
