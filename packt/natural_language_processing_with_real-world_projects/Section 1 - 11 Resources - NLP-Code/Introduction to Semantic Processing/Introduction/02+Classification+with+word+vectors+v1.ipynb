{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca3dbcd-5443-4ab7-b7a1-e631b8a42abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f43d4f2-d8cd-4f9b-9d1d-7433fe3a223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Simon\\\\packt_video_courses\\\\Natural-Language-Processing-with-Real-World-Projects\\\\Section 1 - 11 Resources - NLP-Code\\\\Introduction to Semantic Processing\\\\Introduction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592b969-5964-4bd8-a886-a9a0fb84132f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d679981-e27b-4bb5-a602-7c168d07dbfd",
   "metadata": {},
   "source": [
    "### Loading the training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8bf980-b13f-47bf-bb59-a522fe2d95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"attachment_r8-train-all-terms_lyst3317.txt\"\n",
    "test_data = \"attachment_r8-test-all-terms_lyst1822.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8ffa69-cb9a-4240-9433-3b2ac4a14514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 5485\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "with open(train_data, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        X.append(text.split())\n",
    "        y.append(label)\n",
    "print(\"total examples %s\" % len(y))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4cbfe0c-9ded-41d3-818c-abdd9b6c019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 2189\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = [], []\n",
    "with open(test_data, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        X_test.append(text.split())\n",
    "        y_test.append(label)\n",
    "print(\"total examples %s\" % len(y_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8aa5b06-cce1-4a0c-9732-3fd300ef361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['acq', 'crude', 'earn', 'grain', 'interest', 'money-fx', 'ship',\n",
       "        'trade'], dtype='<U8'),\n",
       " array([1596,  253, 2840,   41,  190,  206,  108,  251], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3b76a-7b3e-4c49-876b-9d45f7616f7d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06557f-cabc-4e44-8083-df01ead5efa3",
   "metadata": {},
   "source": [
    "### Using NB methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4284468-06a9-42e3-ae75-1c71fa015dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter\n",
      "\n",
      "vieille montagne reports loss dividend nil year net loss after exceptional charges mln francs vs profit mln exceptional provisions for closure of viviez electrolysis plant mln francs vs exceptional gain mln sales and services billion francs vs billion proposed net dividend on ordinary shares nil vs francs company s full name is vieille montagne sa vmnb br reuter\n"
     ]
    }
   ],
   "source": [
    "X_text = [\" \".join(val) for val in X]\n",
    "print(X_text[0] + \"\\n\")\n",
    "X_test_text = [\" \".join(val) for val in X_test]\n",
    "print(X_test_text[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f065bc-d62f-4d34-8ead-ec571ebd995b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e893cbd-2798-4f2c-bfe1-196acfd3a04f",
   "metadata": {},
   "source": [
    "#### Using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71016a5d-0d61-4406-a0e5-f94609e4c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f39a4a-fe6c-4c95-b5d0-7a7d2c2d72a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=5000, stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=5000, stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_features=5000, stop_words='english')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=\"english\", max_features=5000)\n",
    "vect.fit(X_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee1e4b-6b55-4fe5-b288-1d4f0f9998a6",
   "metadata": {},
   "source": [
    "Applying the vectorizer to our test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be9464a-161a-45e5-a8d1-8090c613d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vect.transform(X_text)\n",
    "X_test_transformed = vect.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec57ea11-a7c1-4726-9d9e-1df0f7d74c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('champion', 759),\n",
       " ('products', 3488),\n",
       " ('approves', 264),\n",
       " ('stock', 4337),\n",
       " ('split', 4273),\n",
       " ('said', 3974),\n",
       " ('board', 532),\n",
       " ('directors', 1327),\n",
       " ('approved', 263),\n",
       " ('common', 895)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vect.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e326002-72fd-4d55-b804-2e1e90e21e0c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3a88e-6873-46e8-895e-9cb132588e51",
   "metadata": {},
   "source": [
    "### Using Bernoulli NB first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb8b593-b2ac-4618-81df-f7027cd7f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "893baa9b-04c3-4c4a-be88-4f230912f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8736554238833182\n",
      "Train accuracy:  0.8688899040657835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_transformed, y)\n",
    "\n",
    "#predict class\n",
    "pred_train_ys = bnb.predict(X_train_transformed)\n",
    "pred_test_ys = bnb.predict(X_test_transformed)\n",
    "\n",
    "#accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y, pred_train_ys))\n",
    "print(\"Train accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7df60e-95a8-46db-9fc8-5e737904f0b3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936dad1c-dc89-49b7-9b9e-63d947e69b58",
   "metadata": {},
   "source": [
    "### Using Multinomial NB\n",
    "- We expect this to work very well, giving high performance in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a88dcc7-e197-4211-87d0-c5d42d34d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f10ce2-5ee9-4bc9-8c81-0466ff022d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.968094804010939\n",
      "Train accuracy:  0.9657377798081316\n"
     ]
    }
   ],
   "source": [
    "#fit on training data\n",
    "mnb.fit(X_train_transformed, y)\n",
    "\n",
    "#predict class\n",
    "pred_train_ys = mnb.predict(X_train_transformed)\n",
    "pred_test_ys = mnb.predict(X_test_transformed)\n",
    "\n",
    "#accuracy\n",
    "print(\"Train accuracy: \", accuracy_score(y, pred_train_ys))\n",
    "print(\"Train accuracy: \", accuracy_score(y_test, pred_test_ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59937c34-aa47-404a-9a79-37e3d23f7a02",
   "metadata": {},
   "source": [
    "- as expected, this performed really well\n",
    "- remebmer that we used 5000 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2f612-9a11-4d73-81f9-d1aa736b5e22",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69458b0-7168-4c4a-a730-26bb7c969926",
   "metadata": {},
   "source": [
    "### Using our word embeddings approach\n",
    "\n",
    "We have two option here:\n",
    "1. Use pre-trained word vectors (Glove)\n",
    "2. Train our own vectors\n",
    "\n",
    "We'll explore both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e752fc-b669-43bc-bc8d-84e30cbf0de3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cd422-37d9-431a-b256-566bcee8ddf2",
   "metadata": {},
   "source": [
    "### Loading the pre-trained GloVe word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0279f994-3125-4b8f-927d-36fb1f054cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Simon\\AppData\\Local\\Temp\\ipykernel_15616\\3826241164.py:6: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_input_file = \"F:\\Downloads\\glove.6B\\glove.6B.200d.txt\"\n",
    "word2vec_output_file = \"F:\\Downloads\\glove.6B\\glove.6B.200d.w2vformat.txt\"\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d63e0fb-8fb4-4d27-81c1-81a7b31ee0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea930f7-555e-4662-9741-99e5751bcbfc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4959da3-6171-4e34-b955-9c1301e817cc",
   "metadata": {},
   "source": [
    "### Sentence vector by averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81915ad2-642d-4fc5-9239-0eaf590da808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Simon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1ffa078-4ff0-4489-bf36-fa2e869e6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9572407-7d05-4364-b214-12ee36e41932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec(sent):\n",
    "    wv_res = np.zeros(glove_model.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in glove_model:\n",
    "            ctr += 1    \n",
    "            wv_res += glove_model[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690fc39e-3f7d-455f-b74c-ef70144e5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X:\n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1c91400-85fd-4d07-a213-a660100c930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:\n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_vec(doc_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f40dd1-5b67-4b37-9a82-507823254e6f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee232564-c713-4840-bb9e-e7b6b51a67b9",
   "metadata": {},
   "source": [
    "### Building a predictive model on the averaged word vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa392b0-c7f0-4294-aed9-6c50fb45a726",
   "metadata": {},
   "source": [
    "#### Using a \"simple\" logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "391e89f6-aa26-4222-9d68-5781a1fde38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ab1867a-a1f2-4e47-9a9a-c89d2e24132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=3.5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3.5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=3.5, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty=\"l2\", random_state=42, C=3.5)\n",
    "logreg.fit(train_doc_vecs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ae245f4-c120-47ea-811f-77994372e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9797629899726527\n",
      "Test accuracy:  0.9680219278209228\n"
     ]
    }
   ],
   "source": [
    "pred_train_ys = logreg.predict(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict(test_doc_vecs)\n",
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ebdc0c-1e5f-454d-b483-b6d4c1127ef5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd5123-4366-426f-a51a-6fc3667469b3",
   "metadata": {},
   "source": [
    "### Training our own word vectors on the data\n",
    "We'll create a combined text file to train our word vectors - more data is better. Although in this case we would still have just 7.7K instances to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127eace4-6878-4948-9082-645492434a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5485,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_comb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X, X_test])\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5485,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X_comb = np.concatenate([X, X_test])\n",
    "#len(X_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8be207e-51ec-4287-94d4-5a5fb5d23778",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_comb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_comb[\u001b[38;5;241m6000\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_comb' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_comb[6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e8516-9f74-4127-8d3c-34040d1092d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = word2vec.Word2Vec(X_comb, window=2, min_count=2, sg=1, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba60354-c9e8-40a7-96d9-e1f51beac0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(\"future\", topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70efaa6-723d-4678-aad2-0dbcfbd43fb0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a050b0-bd84-4496-a0b8-130032701599",
   "metadata": {},
   "source": [
    "####  Sentence vectors by averaging vectors for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78584fe-9838-4a0f-9816-ca6355eb7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vec_w2v(sent):\n",
    "    wv_res = np.zeros(w2v.vector_size)\n",
    "    ctr = 1\n",
    "    for w in sent:\n",
    "        if w in w2v:\n",
    "            ctr+=1\n",
    "            wv_res += w2v[w]\n",
    "    wv_res = wv_res/ctr\n",
    "    return wv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ea5b0-3d1a-4cd5-bdd9-e58827048165",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86a879-1e78-4722-a8e0-9d3a40ee75a8",
   "metadata": {},
   "source": [
    "#### Getting the sentence vectors for the test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f954f-34d5-4a87-801e-4732e5f6e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_vecs = []\n",
    "for doc in X:\n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    train_doc_vecs.append(sent_voc_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa567479-af9b-43b9-89d4-63892eb6da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc_vecs = []\n",
    "for doc in X_test:\n",
    "    doc_words = [term for term in doc if term not in stop_words]\n",
    "    test_doc_vecs.append(sent_voc_w2v(doc_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0f4bb-545a-4bb9-b03e-228e839e2e0c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763d929-ccb9-4132-a6cb-afee348c8ad0",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddbc56-6db5-4cef-a1be-d6fbdc7eb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c69e29-f0fc-4a17-a881-4ae3277fa9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty=\"l1\", random_state=42, C = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2eee4-b77d-4950-b676-133fca61c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(train_doc_vecs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a17347-9ece-41b8-9701-073ae4792cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_ys = logreg.predict(train_doc_vecs)\n",
    "pred_test_ys = logreg.predict(test_doc_vecs)\n",
    "print(\"Train accuracy: \", accuracy_score(pred_train_ys, y))\n",
    "print(\"Test accuracy: \", accuracy_score(pred_test_ys, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
