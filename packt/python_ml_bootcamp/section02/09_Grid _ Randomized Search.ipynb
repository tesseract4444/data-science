{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data= fetch_openml('mnist_784', version=1, parser=\"auto\")#Get data from https://www.openml.org/d/554\n",
    "dfData = pd.DataFrame(np.c_[data[\"data\"],data[\"target\"]],columns = data[\"feature_names\"]+[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in stratSplit.split(dfData[data[\"feature_names\"]], dfData[\"target\"]):\n",
    "    X_train = dfData[data[\"feature_names\"]].iloc[train_index]\n",
    "    X_test = dfData[data[\"feature_names\"]].iloc[test_index]\n",
    "    \n",
    "    y_train = dfData[\"target\"].iloc[train_index]\n",
    "    y_test = dfData[\"target\"].iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = [{\"penalty\":[\"l1\"], \"C\":[0.1,1,10]}] #my thing\n",
    "          #[{\"penalty\":[\"l1\",\"l2\"],\"C\":[0.1,1,10]}]#,\n",
    "          #{\"penalty\":[\"elasticnet\"],\"C\":[0.1,1,10, 100],\"l1_ratio\":[0.1,0.3]}] #\"max_iter\":[100]\n",
    "\n",
    "#grid search is going through all the combinations of parameters\n",
    "logreg_clf_gscv = GridSearchCV(estimator=LogisticRegression(solver=\"liblinear\"), #got to use \"liblinear\" or it will cause a solver=lbfgs error\n",
    "                       param_grid=params,\n",
    "                        scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                    \n",
    "                       refit=\"roc_auc_ovr_weighted\",#True #here: looking for the best model on roc_auc_ovr_weighted score\n",
    "                        cv = 3,#If our estimator is classifier automatically do stratified CV\n",
    "                        n_jobs=-1,#Num CPUs to use for calculation, -1 means all\n",
    "                        verbose = 0,#Output status updates, higher number-> more messages\n",
    "                        return_train_score=True#if false our results won't contain training scores\n",
    "                              )\n",
    "logreg_clf_gscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg_clf_gscv.cv_results_.keys()) #read the stats you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsCVDF = pd.DataFrame(logreg_clf_gscv.cv_results_)\n",
    "print(resultsCVDF.sort_values(\"mean_fit_time\",ascending=True)) #display the stats for mean_fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_index_ #only with refit for multi-scoring cases\n",
    "resultsCVDF.iloc[logreg_clf_gscv.best_index_] #display the best index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the best performing model\n",
    "print(logreg_clf_gscv.best_estimator_) #only with refit\n",
    "logreg_clf_gscv.best_estimator_.predict(X_train) #access the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the best score and the best parameters\n",
    "print(logreg_clf_gscv.best_score_) #only with refit for multi-scoring cases\n",
    "print(logreg_clf_gscv.best_params_) #only with refit for multi-scoring cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives us the exact parameters used for our training model\n",
    "logreg_clf_gscv.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way to make predictions from the model\n",
    "logreg_clf_gscv.predict(X_train)#only when refit is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random choice via RandomizedSearchCV: so much faster!\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logreg_clf_rscv = RandomizedSearchCV(estimator = LogisticRegression(),\n",
    "                       param_distributions = params,\n",
    "                        n_iter = 10,# num param settings sampled\n",
    "                        random_state = None,#if not none uses this integer as seed\n",
    "                        scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                    \n",
    "                       refit=\"roc_auc_ovr_weighted\",#True\n",
    "                        cv = 3,#If our estimator is classifier automatically do stratified CV\n",
    "                        n_jobs=-1,#Num CPUs to use for calculation, -1 means all\n",
    "                        verbose = 0,#Output status updates, higher number-> more messages\n",
    "                        return_train_score=True#if false our results won't contain training scores\n",
    "                              )\n",
    "logreg_clf_rscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsRSDF = pd.DataFrame(logreg_clf_rscv.cv_results_)\n",
    "print(resultsRSDF.sort_values(\"mean_fit_time\",ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\"penalty\":[\"l1\"],\"C\":[1],\"solver\":[\"saga\"]}]\n",
    "\n",
    "# params = [{\"penalty\":[\"l1\"],\"C\":[0.1,1,10],\"solver\":[\"saga\"]},\n",
    "#          {\"penalty\":[\"l2\"],\"C\":[0.1,1,10],\"solver\":[\"saga\"]},\n",
    "#          {\"penalty\":[\"l2\"],\"C\":[0.1,1,10],\"solver\":[\"lbfgs\"]}]\n",
    "\n",
    "logreg_clf_gscv = GridSearchCV(estimator=LogisticRegression(),\n",
    "                       param_grid=params,\n",
    "                        scoring = [\"accuracy\",\"roc_auc_ovr_weighted\",\"f1_macro\"],\n",
    "                    \n",
    "                       refit=\"roc_auc_ovr_weighted\",#True\n",
    "                        cv = 3,#If our estimator is classifier automatically do stratified CV\n",
    "                        n_jobs=-1,#Num CPUs to use for calculation, -1 means all\n",
    "                        verbose = 0,#Output status updates, higher number-> more messages\n",
    "                        return_train_score=True#if false our results won't contain training scores\n",
    "                              )\n",
    "logreg_clf_gscv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(logreg_clf_gscv.cv_results_).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
