{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jn_4OSPi6al5","executionInfo":{"status":"ok","timestamp":1708338656433,"user_tz":-60,"elapsed":85338,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"2c662fe5-e0f8-427b-88e9-bfa96047da6f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.tree import DecisionTreeClassifier\n","\n","data = fetch_openml('mnist_784', version=1)#Get data from https://www.openml.org/d/554\n","dfData = pd.DataFrame(np.c_[data[\"data\"],data[\"target\"]],columns = data[\"feature_names\"]+[\"target\"])"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZW1hRkf46al8","executionInfo":{"status":"ok","timestamp":1708338669601,"user_tz":-60,"elapsed":9730,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}}},"outputs":[],"source":["stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","for train_index, test_index in stratSplit.split(dfData[data[\"feature_names\"]], dfData[\"target\"]):\n","    X_train = dfData[data[\"feature_names\"]].iloc[train_index]\n","    X_test = dfData[data[\"feature_names\"]].iloc[test_index]\n","\n","    y_train = dfData[\"target\"].iloc[train_index]\n","    y_test = dfData[\"target\"].iloc[test_index]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"sg3te44r6al9","executionInfo":{"status":"ok","timestamp":1708339146913,"user_tz":-60,"elapsed":458519,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"84260c52-e269-46ea-c99a-d7f8ccbc13df"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n","                                                        max_features='sqrt',\n","                                                        splitter='random'),\n","                  max_features=0.9, max_samples=0.8, n_estimators=30, n_jobs=2,\n","                  random_state=0)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n","                                                        max_features=&#x27;sqrt&#x27;,\n","                                                        splitter=&#x27;random&#x27;),\n","                  max_features=0.9, max_samples=0.8, n_estimators=30, n_jobs=2,\n","                  random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n","                                                        max_features=&#x27;sqrt&#x27;,\n","                                                        splitter=&#x27;random&#x27;),\n","                  max_features=0.9, max_samples=0.8, n_estimators=30, n_jobs=2,\n","                  random_state=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_features=&#x27;sqrt&#x27;, splitter=&#x27;random&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_features=&#x27;sqrt&#x27;, splitter=&#x27;random&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":3}],"source":["from sklearn.ensemble import BaggingClassifier\n","\n","#soft voting by default if predict_proba method exists\n","bag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3,\n","                                                      max_features='sqrt',\n","                                                      splitter='random'),\n","                            n_estimators=30,  #30 different decision tree classifiers\n","                            max_samples=0.8,  # int(e.g.100 = 100 different samples)/float, default with replacement, size of the subset of the training data we give to each model during training\n","                                              # maximum training set sample size compared to original training set (80% of original training set)\n","                            max_features=0.9, # int(e.g. 100 = 100 different features)/float, default without replacement, define the random subspaces\n","                                              # maximum feature size compared to original number of features\n","                            bootstrap=True,   # bagging (= set to True)/pasting (= set to False) (affects max_samples behaviour)\n","                            bootstrap_features=False, # if feature selection should use bagging (max_features), random sampling the features without replacement\n","                            oob_score=False,  # perform oob scoring (oob=out-of-bag), it will slightly increase training times just because then youalso have to perform the predictions and evaluate them\n","                            warm_start=False,\n","                            n_jobs=2,\n","                            random_state=0,\n","                            verbose=0\n","                            )\n","\n","bag_clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zr8S7aRs6al_","executionInfo":{"status":"ok","timestamp":1708339173513,"user_tz":-60,"elapsed":307,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"0ec94f84-eef4-4e5c-a557-c48e41858a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["30\n","30\n","30\n"]}],"source":["print(len(bag_clf.estimators_)) # array of trained estimators\n","print(len(bag_clf.estimators_samples_)) # array of sample subsets used to train each estimator\n","print(len(bag_clf.estimators_features_)) # array of feature subsets used to train each estimator\n","\n","# #when oob_score is true we also get the out-of-bag score\n","# bag_clf.oob_score_\n","# bag_clf.oob_decision_function_"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VhtKmqnX6amB","executionInfo":{"status":"ok","timestamp":1708339498132,"user_tz":-60,"elapsed":63127,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}}},"outputs":[],"source":["#iteration over all of our estimators because each estimator is trained on a subset of features\n","#we need to make sure we iterate over the features\n","scores = []\n","for est,features in zip(bag_clf.estimators_,bag_clf.estimators_features_):\n","    scores.append(est.score(X_test.values[:, features], y_test.astype(np.float64))) #score it on the testing set only using the relevant features\n","    # Sklearn transform str for of integers to np.float64 internally (because it's treated originally as a float)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmDpqW0a6amC","executionInfo":{"status":"ok","timestamp":1708339505901,"user_tz":-60,"elapsed":297,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"3bd7ee9d-189c-4040-d234-9fbe0dfdc296"},"outputs":[{"output_type":"stream","name":"stdout","text":["Avg. estimator performance: 0.35524999999999995\n","Estimaor performance std. dev.: 0.025101865597253623\n"]}],"source":["print('Avg. estimator performance:',np.mean(scores)) #=accuracy\n","print('Estimaor performance std. dev.:',np.std(scores))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hagfLXaX6amC","executionInfo":{"status":"ok","timestamp":1708339809266,"user_tz":-60,"elapsed":117408,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"2687648e-0299-45fb-d471-ed723d6c9264"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6851428571428572"]},"metadata":{},"execution_count":8}],"source":["bag_clf.score(X_test, y_test)"]},{"cell_type":"markdown","source":["Even though what we're doing here is we're doing a ton of randomization and eachdecision tree only gets a subset of the samples and a subset of the features.And it even performs splitting randomly ratherthan trying to find the best splitter,we still get a huge performance boost.UmAnd yeah, that's the power that we can get from ensemble methods. Don't forget to use grid search to find optimal parameters (finding a good balance between training time and performance) which can lead to a better final performance (here: better than 0.685)."],"metadata":{"id":"XQ8JayHR_eTd"}},{"cell_type":"code","source":[],"metadata":{"id":"R1BFPcGu_fBi"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}