{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoTtoZW4SkL9","executionInfo":{"status":"ok","timestamp":1708596625271,"user_tz":-60,"elapsed":64548,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"b855c13c-a958-4662-e796-56edb405e794"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","\n","data = fetch_openml('mnist_784', version=1)#Get data from https://www.openml.org/d/554\n","dfData = pd.DataFrame(np.c_[data[\"data\"],data[\"target\"]],columns = data[\"feature_names\"]+[\"target\"])"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2xbmLDK9SkMD","executionInfo":{"status":"ok","timestamp":1708596646507,"user_tz":-60,"elapsed":5756,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}}},"outputs":[],"source":["stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","\n","for train_index, test_index in stratSplit.split(dfData[data[\"feature_names\"]], dfData[\"target\"]):\n","    X_train = dfData[data[\"feature_names\"]].iloc[train_index]\n","    X_test = dfData[data[\"feature_names\"]].iloc[test_index]\n","\n","    y_train = dfData[\"target\"].iloc[train_index]\n","    y_test = dfData[\"target\"].iloc[test_index]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"rhYU3R4XSkME","executionInfo":{"status":"error","timestamp":1708597860198,"user_tz":-60,"elapsed":1112187,"user":{"displayName":"Sim Don","userId":"09290070938786203900"}},"outputId":"0a14e692-c5f3-4f57-b0e3-a045f88535b6"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ae6ec6e36381>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mstacked_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[0;32m--> 252\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    254\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from sklearn.ensemble import StackingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","#3 estimators (DT, SVC, LR)\n","stacked_clf = StackingClassifier(estimators=[('dt_depth8',DecisionTreeClassifier(max_depth=8)), #name of estimator, initialized estimator\n","                                               ('rbf_svc',SVC()),\n","                                               ('log_reg',LogisticRegression())],\n","                                    final_estimator=RandomForestClassifier(), #estimator we use for blending\n","                                    cv=5, # split for holdout set, play around by reducing it\n","                                    stack_method='auto', # which function to call when doing the prediction\n","                                                         # uses 'predict_proba', 'decision_function', 'predict'\n","                                                         # in that order (for each estimator separately)\n","                                    n_jobs=2,\n","                                    passthrough=False, # if final estimator should use raw training inputs\n","                                                       # in addition to estimators layer prediction output\n","                                                       #note: if True training layer would also fet into 2nd layer\n","                                                       #into aggregation layer in addition to the outputs of our base layer\n","                                                       #can lead to improvements, but: higher computation time!\n","                                    verbose=0\n","                                    )\n","\n","stacked_clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbKO-LV1SkMH","outputId":"ffae7730-ae14-47be-e76b-f4f5bc7b8403"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dt_depth8': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=8, max_features=None, max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=None, splitter='best'), 'rbf_svc': SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False), 'log_reg': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)}\n","RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)\n","['predict_proba', 'decision_function', 'predict_proba']\n"]}],"source":["print(stacked_clf.named_estimators_)\n","print(stacked_clf.final_estimator_)\n","print(stacked_clf.stack_method_) # prediction method used by each estimator\n","\n","#results:\n","#predict_proba for DT, decision_funcion for SVC, predict_proba for LR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGENvifASkMJ","outputId":"05fec850-6d7e-4f6f-e0c0-57be7ca4d3e7"},"outputs":[{"data":{"text/plain":["0.9800714285714286"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#get the accuracy on the test set\n","stacked_clf.score(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9LzPoN2SkMK","outputId":"73a95144-4598-44de-8d0a-c26fe61b4bb3"},"outputs":[{"data":{"text/plain":["StackingClassifier(cv=None,\n","                   estimators=[('dt_depth8',\n","                                DecisionTreeClassifier(ccp_alpha=0.0,\n","                                                       class_weight=None,\n","                                                       criterion='gini',\n","                                                       max_depth=8,\n","                                                       max_features=None,\n","                                                       max_leaf_nodes=None,\n","                                                       min_impurity_decrease=0.0,\n","                                                       min_impurity_split=None,\n","                                                       min_samples_leaf=1,\n","                                                       min_samples_split=2,\n","                                                       min_weight_fraction_leaf=0.0,\n","                                                       presort='deprecated',\n","                                                       random_state=None,\n","                                                       splitter='best')),\n","                               (...\n","                                                                                             max_leaf_nodes=None,\n","                                                                                             max_samples=None,\n","                                                                                             min_impurity_decrease=0.0,\n","                                                                                             min_impurity_split=None,\n","                                                                                             min_samples_leaf=1,\n","                                                                                             min_samples_split=2,\n","                                                                                             min_weight_fraction_leaf=0.0,\n","                                                                                             n_estimators=100,\n","                                                                                             n_jobs=None,\n","                                                                                             oob_score=False,\n","                                                                                             random_state=None,\n","                                                                                             verbose=0,\n","                                                                                             warm_start=False),\n","                                                      n_jobs=2,\n","                                                      passthrough=False,\n","                                                      stack_method='auto',\n","                                                      verbose=0),\n","                   n_jobs=2, passthrough=False, stack_method='auto', verbose=0)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#for multilayer stacked models use GradientBoostingClastifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","final_layers_clf = StackingClassifier(estimators=[('rand_forest',RandomForestClassifier(max_depth=3)),\n","                                               ('grad_boost',GradientBoostingClassifier(max_depth=3))],\n","                                    final_estimator=RandomForestClassifier(),\n","                                    n_jobs=2\n","                                    )\n","\n","#same as above\n","stack_base_clf = StackingClassifier(estimators=[('dt_depth8',DecisionTreeClassifier(max_depth=8)),\n","                                               ('rbf_svc',SVC()),\n","                                               ('log_reg',LogisticRegression())],\n","                                    final_estimator=final_layers_clf, #changed now: call the stacking classifiers above as finaly layers\n","                                    n_jobs=2\n","                                    )\n","stack_base_clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIJP2617SkML","outputId":"c62f9ba0-7b16-4567-85c7-b81e93dfbe5a"},"outputs":[{"data":{"text/plain":["0.9795"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["stack_base_clf.score(X_test, y_test)"]},{"cell_type":"markdown","source":["Adding more layers doesn't seem to improve our accuracy. Adding (much) more layers can lead to overfitting and cause performance issues. Nevertheless we have to put enough data into the holdout set to feed the subsequent layers."],"metadata":{"id":"F5DaluSeYJQx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqGkYwjwSkMM"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}