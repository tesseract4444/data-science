{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7668e13",
   "metadata": {},
   "source": [
    "#### Abschnitt 1: Inverted Index mit Ausgabe der TFIDF-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#definieren der funktion für den inverted index\n",
    "def inverted_index(documents):\n",
    "    inverted_index = {}\n",
    "\n",
    "    for document in documents:\n",
    "        text = document[\"text\"]\n",
    "        document_name = document[\"name\"]\n",
    "\n",
    "        # text tokenisieren über re.findall, zahlen im text werden nicht berücksichtigt\n",
    "        terms = re.findall(r'\\w+', text.lower())\n",
    "\n",
    "        # den tfidfVectorizer über sklearn festlegen zur berechnung\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "        # terme und ihre tf-idf-werte berechnen lassen\n",
    "        # matrix in ein array umwandeln, zugriff auf immer ein dokument\n",
    "        terms = vectorizer.get_feature_names_out()\n",
    "        tfidf_values = tfidf_matrix.toarray()[0]\n",
    "\n",
    "        # dokument, terme und tf-idf-werte zusammenfügen beim inverted index für spätere ausgabe\n",
    "        for term, tfidf in zip(terms, tfidf_values):\n",
    "            if term.isdigit():  # überprüfung, ob der term eine zahl ist, falls ja: überspringen\n",
    "                continue\n",
    "            if term not in inverted_index:\n",
    "                inverted_index[term] = []\n",
    "            inverted_index[term].append((document_name, tfidf))\n",
    "\n",
    "    return inverted_index\n",
    "\n",
    "# pfad einfügen lassen und leere liste erstellen zum einlesen\n",
    "path2corpus = input(\"Bitte den genauen Pfad hier einfügen...\")\n",
    "documents = []\n",
    "\n",
    "# einlesen der dokumente über name und text in form eines dictionary\n",
    "for file_name in tqdm(os.listdir(path2corpus), desc=\"Einlesen der Dokumente...\"):\n",
    "    with open(os.path.join(path2corpus, file_name), \"r\", encoding=\"utf-8\") as file:\n",
    "        document = {\n",
    "            \"name\": file_name,\n",
    "            \"text\": file.read()\n",
    "        }\n",
    "        documents.append(document)\n",
    "        \n",
    "\n",
    "#inverted-index-funktion auf die dokumente anwenden\n",
    "inverted_index = inverted_index(documents)\n",
    "\n",
    "        \n",
    "#gibt den inverted index in der endausgabe aus mit term übergeordnet und darunter...\n",
    "#...die auflistung der jeweiligen dateinamen und des tfidf\n",
    "for term, key in inverted_index.items():\n",
    "    print(f\"Term: {term}\")\n",
    "    for key in key:\n",
    "        document_name, tfidf = key\n",
    "        print(f\"\\tDateiname: {document_name}, TFIDF: {tfidf}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df312db",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca244cb",
   "metadata": {},
   "source": [
    "#### Abschnitt 2: Vektorraum-Modell über Kosinus-Ähnlichkeiten der TFIDF-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "#pfad zum verzeichnis mit den Dokumenten\n",
    "path2corpus = input(\"Bitte geben Sie den Pfad zum Verzeichnis mit den Dokumenten ein: \")\n",
    "\n",
    "#dokumente einlesen\n",
    "documents = []\n",
    "file_names = []\n",
    "for file_name in tqdm(os.listdir(path2corpus), desc=\"Einlesen der Dokumente\"):\n",
    "    with open(os.path.join(path2corpus, file_name), \"r\", encoding=\"utf-8\") as file:\n",
    "        document = file.read()\n",
    "        documents.append(document)\n",
    "        file_names.append(file_name)\n",
    "\n",
    "#tfidfVectorizer über von sklearn definieren\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# dokumentdaten in eine tfidf-matrix umwandeln\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "#feature_names berechnen lassen (vocabulary)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "#wortsuche über while-schleife durchführen\n",
    "while True:\n",
    "    input_word = input(\"Finde folgendes Wort: \")\n",
    "    if not input_word:\n",
    "        print(\"Kein Wort eingegeben. Das Programm wird abgebrochen.\")\n",
    "        break\n",
    "    else:\n",
    "        #input_word = input_word.split()    \n",
    "    \n",
    "        #vektor für eingabewort berechnen\n",
    "        base_vector = vectorizer.transform([input_word])\n",
    "\n",
    "        #tfidf-werte für das eingabewort abrufen\n",
    "        base_tfidf = base_vector.toarray()[0]\n",
    "\n",
    "        #cosinus-ahnlichkeit zwischen eingabewortvektor und dokumentvektoren berechnen\n",
    "        cosine_sim = cosine_similarity(base_vector, tfidf_matrix)\n",
    "\n",
    "        #ähnlichkeitswerte für das eingabewort für alle dokumente bekommen\n",
    "        similarity_scores = cosine_sim.flatten()\n",
    "\n",
    "        #indizes der nicht-null ähnlichkeitswerte erhalten, um 0er auszufiltern\n",
    "        filter_zeroes = np.nonzero(similarity_scores)\n",
    "\n",
    "        #filtern der ähnlichkeitswerte, tfidf-matrix und dateinamen\n",
    "        filter_cosine = similarity_scores[filter_zeroes]\n",
    "        filter_filenames = np.array(file_names)[filter_zeroes]\n",
    "\n",
    "        #gefilterte kosinus-ähnlichkeiten absteigend sortieren mithilfe von umgekehrtem slicing [::-1]\n",
    "        sorted_indices = np.argsort(filter_cosine)[::-1]\n",
    "\n",
    "        #10 häufigste nonzero kosinus-ähnlichkeitswerte und summe der entsprechenden tfidf-werte ausgeben\n",
    "        if len(sorted_indices) == 0:\n",
    "            print(\"Wort nicht im Korpus enthalten.\\n\") \n",
    "        else:    \n",
    "            print(\"10 häufigste TF-IDF-Werte, berechnet über die Kosinus-Ähnlichkeit:\")\n",
    "            for index in sorted_indices[:10]:\n",
    "                file_name = filter_filenames[index]\n",
    "                similarity = filter_cosine[index]\n",
    "                if similarity != [0.]: #nicht-0-werte definieren für ausgabe\n",
    "                    print(f'Dokument: {file_name}, Cos-Ähnlichkeit: {similarity}\\n')\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d111990",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88edfbb0",
   "metadata": {},
   "source": [
    "requirements.txt nicht als Abgabe möglich wegen Abgabebegrenzung in WueCampus, daher hier als Kommentar eingefügt:\n",
    "\n",
    "- numpy==1.23.5\n",
    "- tqdm==4.65.0\n",
    "- scikit-learn==1.1.3\n",
    "- re==2.2.1\n",
    "- pandas=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e5553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
