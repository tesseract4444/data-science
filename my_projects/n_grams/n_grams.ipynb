{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bd6236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Code:\n",
      "0.006899350649350649\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Union, Dict\n",
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "\n",
    "with open(\"names.txt\") as f:\n",
    "    names = [line.strip() for line in f if line]\n",
    "#print(f\"Number of names: {len(names)}\")\n",
    "#print(names[::1000])\n",
    "\n",
    "class NamesDataset:\n",
    "    \"\"\"\n",
    "    Implement all methods in this class,\n",
    "    such that the output type fulfills the type annotations\n",
    "    and their behavior follows the description in the doc-strings. \n",
    "    \"\"\"\n",
    "    def __init__(self, names: List[str]):\n",
    "        \"\"\"\n",
    "        The constructor must save the names as an attribute.\n",
    "        \"\"\"\n",
    "        self.names = names\n",
    "    \n",
    "    def query(self, prefix: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        The query method takes in a prefix and returns a list \n",
    "        of all names in the dataset that start with the given prefix.\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in names:\n",
    "            if i.startswith(prefix):\n",
    "                print(i)\n",
    "    \n",
    "    def longest_name(self, prefix: str = None, return_len: bool = False) -> Union[str, Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        The longest_name method returns the longest name in the dataset.\n",
    "        \n",
    "        It also must support filtering the names by the prefix.\n",
    "        If a prefix is given, than it should return the longest name, starting with the prefix\n",
    "        \n",
    "        Additionally, if the return_len argument is True, it should output the longest name. \n",
    "        AND its length (as tuple). \n",
    "        \"\"\"\n",
    "        return max(names, key=len), len(max(names, key=len))\n",
    "    \n",
    "    def mean_name_length(self) -> float:\n",
    "        \"\"\"\n",
    "        This method computes the mean length of all names in the dataset.\n",
    "        \"\"\"\n",
    "        sum_it = []\n",
    "        for i in names:\n",
    "            all = len(i)\n",
    "            sum_it.append(all)\n",
    "        print(np.mean(sum_it))\n",
    "       \n",
    "    \n",
    "    def ngrams(self, size: int, prefix: str = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        This method returns a list of all character n_grams of all names (or those starting with a given prefix).\n",
    "        The size determines the size of the n_grams.\n",
    "        \"\"\"\n",
    "        n_grams = ngrams(names, size)\n",
    "        list_convert = list(n_grams)\n",
    "        #print(list_convert)\n",
    "        neue_liste = []\n",
    "        \n",
    "        for i in list_convert:\n",
    "            for j in i:\n",
    "                if j.startswith(prefix):\n",
    "                    neue_liste.append(j)\n",
    "                    clean = [*set(neue_liste)]\n",
    "        clean2 = ngrams(clean, size)\n",
    "        print(list(clean2))\n",
    "        \n",
    "        \n",
    "    def count_ngrams(self, size: int, prefix: str = None) -> List[Tuple[str, int]]:\n",
    "        \"\"\"\n",
    "        This method returns a list of tuples containing all n_grams created with the given arguments\n",
    "        and their frequency within all n_grams found under the parameters.\n",
    "        The list should be sorted in ascending order.\"\"\"\n",
    "        \n",
    "        n_grams = ngrams(names, size)\n",
    "        list_convert = list(n_grams)\n",
    "        #print(list_convert)\n",
    "        neue_liste = []\n",
    "        \n",
    "        for i in list_convert:\n",
    "            for j in i:\n",
    "                if j.startswith(prefix):\n",
    "                    neue_liste.append(j)\n",
    "                    clean = [*set(neue_liste)]\n",
    "        clean2 = ngrams(clean, size)\n",
    "        #print(list(clean2))\n",
    "        \n",
    "        return len(list(clean))/len(list_convert)\n",
    "        \n",
    "        \n",
    "print('Check Code:')\n",
    "#print(NamesDataset.query('','a'))\n",
    "#print(NamesDataset.longest_name(1))\n",
    "#print(NamesDataset.mean_name_length(1))\n",
    "#print(NamesDataset.ngrams(1, 2, 'av'))\n",
    "#print(NamesDataset.count_ngrams(1, 2, 'av'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e08fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f35a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
